---
---


@STRING{CVPR = {Proc. IEEE Conf. on Computer Vision and Pattern	Recognition (CVPR)}}
@STRING{ECCV = {Proc. of the European Conf. on Computer Vision (ECCV)}}
@STRING{ICCV = {Proc. of the IEEE International Conf. on Computer Vision (ICCV)}}
@STRING{THREEDV = {Proc. of the International Conf. on 3D Vision (3DV)}}
@STRING{NEURIPS = {Advances in Neural Information Processing Systems (NeurIPS)}}
@STRING{ARXIV = {arXiv.org}}
@STRING{ICLR = {Proc. of the International Conf. on Learning Representations (ICLR)}}

@inproceedings{TBME2022,
  author    = {Puxun Tu, Chunxia Qin, Yan Guo, Dongyuan Li, Abel J Lungu, Huixiang Wang, Xiaojun Chen*},
  title     = {Ultrasound image guided and mixed reality-based surgical system with real-time soft tissue deformation computing for robotic cervical pedicle screw placement},
  booktitle   =  IEEE Transactions on Biomedical Engineering,
  year      = {2022},
  img            = {assets/img/publications/inserf.jpg},
}

@inproceedings{shahbazi2024inserf,
  author    = {Shahbazi, Mohamad and Claessens, Liesbeth and Niemeyer, Michael and Collins, Edo and Tonioni, Alessio and Van Gool, Luc and Tombari, Federico},
  title     = {InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes},
  booktitle   =  ARXIV,
  year      = {2024},
  html = {https://mohamad-shahbazi.github.io/inserf/},
  pdf = {https://arxiv.org/pdf/2401.05335.pdf},
  img            = {assets/img/publications/inserf.jpg},
}


@InProceedings{Mescheder2019CVPR,
  author         = {Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger},
  title          = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
  booktitle      = CVPR,
  year           = {2019},
  abstract       = {With the advent of deep neural networks, learning-based approaches for 3D~reconstruction have gained popularity. However, unlike for images, in 3D there is no canonical representation which is both computationally and memory efficient yet allows for representing high-resolution geometry of arbitrary topology. Many of the state-of-the-art learning-based 3D~reconstruction approaches can hence only represent very coarse 3D geometry or are limited to a restricted domain. In this paper, we propose Occupancy Networks, a new representation for learning-based 3D~reconstruction methods. Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classifier. In contrast to existing approaches, our representation encodes a description of the 3D output at infinite resolution without excessive memory footprint. We validate that our representation can efficiently encode 3D structure and can be inferred from various kinds of input. Our experiments demonstrate competitive results, both qualitatively and quantitatively, for the challenging tasks of 3D reconstruction from single images, noisy point clouds and coarse discrete voxel grids. We believe that occupancy networks will become a useful tool in a wide variety of learning-based 3D tasks.},
  blog    = {https://autonomousvision.github.io/occupancy-networks/},
  code = {https://github.com/LMescheder/Occupancy-Networks},
  img            = {assets/img/publications/onet.jpg},
  pdf            = {http://www.cvlibs.net/publications/Mescheder2019CVPR.pdf},
  supp           = {http://www.cvlibs.net/publications/Mescheder2019CVPR_supplementary.pdf},
  video          = {http://www.youtube.com/watch?v=w1Qo3bOiPaE&t=6s&vq=hd1080&autoplay=1},
  poster = {http://www.cvlibs.net/publications/Mescheder2019CVPR_poster.pdf},
  html = {https://avg.is.mpg.de/publications/occupancy-networks},
  award = {Oral Presentation, Best Paper Finalist},
}


